{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from datasets import cve_diseases\n",
    "from nets import inception_resnet_v2\n",
    "from nets import alexnet\n",
    "from nets import nets_factory\n",
    "from preprocessing import inception_preprocessing\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIGURE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"inception_resnet_v2\"\n",
    "model2 = \"alexnet_v2\"\n",
    "\n",
    "dataset_name = \"cve_diseases\"\n",
    "dataset_split_name = \"train\"\n",
    "dataset_dir = \"tmp/\"\n",
    "batch_size = 1\n",
    "max_number_of_steps = 2000\n",
    "train_dir = \"./tmp/cve_diseases-models/test-model/\"\n",
    "\n",
    "cnn1 = nets_factory.get_network_fn(\n",
    "    model1,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=True)\n",
    "cnn2 = nets_factory.get_network_fn(\n",
    "    model2,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jonet(images):\n",
    "\n",
    "    net1, end_points1 = cnn1(images)\n",
    "    net2, end_points2 = cnn2(images)\n",
    "    if 'PreAuxLogits' in end_points1:\n",
    "        if 'alexnet_v2/conv4' in end_points2:\n",
    "            \n",
    "            net1 = end_points1['PreAuxLogits']\n",
    "            net1 = slim.conv2d(net1, 256, 1)\n",
    "            net2 = end_points2['alexnet_v2/conv5']\n",
    "            net = tf.concat((net1, net2), 1)\n",
    "            net = slim.flatten(net)\n",
    "            net = slim.dropout(net, 0.8, is_training=True)\n",
    "            net = slim.fully_connected(net, 11, activation_fn=None)\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size=8, height=299, width=299, is_training=False):\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)\n",
    "\n",
    "    image, label = data_provider.get(['image', 'label'])\n",
    "\n",
    "    image = inception_preprocessing.preprocess_image(\n",
    "        image,\n",
    "        height,\n",
    "        width,\n",
    "        is_training)\n",
    "\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        allow_smaller_final_batch=True)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-c86348eb4d15>:23: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /home/johnnyof/.local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From /home/johnnyof/.local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:399: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /home/johnnyof/.local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:152: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_2/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_2/Conv2d_0b_3x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Mixed_7a/Branch_2/Conv2d_1a_3x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_1/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_1/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_1/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_1/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_2/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_2/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_2/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_2/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_3/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_3/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_3/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_3/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_4/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_4/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_4/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_4/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_5/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_5/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_5/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_5/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_6/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_6/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_6/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_6/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_7/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_7/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_7/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_7/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_8/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_8/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_8/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_8/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_9/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_9/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_9/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Repeat_2/block8_9/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Block8/Branch_1/Conv2d_0a_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Block8/Branch_1/Conv2d_0b_1x3/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Block8/Branch_1/Conv2d_0c_3x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var InceptionResnetV2/Conv2d_7b_1x1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var alexnet_v2/fc6/biases has no gradient\n",
      "INFO:tensorflow:Var alexnet_v2/fc7/biases has no gradient\n",
      "WARNING:tensorflow:From /home/johnnyof/.local/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:736: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path ./tmp/cve_diseases-models/test-model/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 1.\n",
      "INFO:tensorflow:global step 100: loss = 3.6806 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 200: loss = 3.6352 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 300: loss = 3.3515 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 400: loss = 3.3474 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 500: loss = 3.0174 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 600: loss = 2.5490 (0.144 sec/step)\n",
      "INFO:tensorflow:global step 700: loss = 3.0248 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 800: loss = 2.4630 (0.142 sec/step)\n",
      "INFO:tensorflow:global step 900: loss = 2.6727 (0.142 sec/step)\n",
      "INFO:tensorflow:global step 1000: loss = 2.4799 (0.139 sec/step)\n",
      "INFO:tensorflow:global step 1100: loss = 2.5566 (0.162 sec/step)\n",
      "INFO:tensorflow:global step 1200: loss = 2.6077 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 1300: loss = 2.4614 (0.139 sec/step)\n",
      "INFO:tensorflow:global step 1400: loss = 2.3541 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 1500: loss = 2.6529 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 1600: loss = 2.3054 (0.140 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 1700: loss = 2.4899 (0.141 sec/step)\n",
      "INFO:tensorflow:global step 1800: loss = 2.1355 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 1900: loss = 2.2686 (0.140 sec/step)\n",
      "INFO:tensorflow:global step 2000: loss = 2.4706 (0.140 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.470629"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Select dataset\n",
    "dataset = cve_diseases.get_split('train', dataset_dir)\n",
    "\n",
    "#Load batch\n",
    "images, labels = load_batch(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    is_training=True)\n",
    "\n",
    "# run the image through the model\n",
    "\n",
    "logits = jonet(images)\n",
    "\n",
    "\n",
    "# get the cross-entropy loss\n",
    "one_hot_labels = slim.one_hot_encoding(\n",
    "    labels,\n",
    "    dataset.num_classes)\n",
    "\n",
    "slim.losses.softmax_cross_entropy(\n",
    "    logits,\n",
    "    one_hot_labels)\n",
    "\n",
    "#tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "#    _sentinel=None,\n",
    "#    labels=labels,\n",
    "#    logits=logits,\n",
    "#    dim=-1,\n",
    "#    name=None\n",
    "#)\n",
    "\n",
    "\n",
    "total_loss = tf.losses.get_total_loss()\n",
    "tf.summary.scalar('loss', total_loss)\n",
    "\n",
    "# use RMSProp to optimize\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9)\n",
    "\n",
    "# create train op\n",
    "train_op = slim.learning.create_train_op(\n",
    "    total_loss,\n",
    "    optimizer,\n",
    "    summarize_gradients=True)\n",
    "\n",
    "# run training\n",
    "slim.learning.train(\n",
    "    train_op,\n",
    "    logdir=train_dir,\n",
    "    number_of_steps=max_number_of_steps,\n",
    "    log_every_n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper funcs\n",
    "for endpoint in end_points1:\n",
    "    print(\"Endpoint: %s - Shape: %s\" % (endpoint, end_points1[endpoint].get_shape()))\n",
    "print(\"###############################\")\n",
    "for endpoint in end_points2:\n",
    "    print(\"Endpoint: %s - Shape: %s\" % (endpoint , end_points2[endpoint].get_shape()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
