{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from datasets import cve_diseases\n",
    "from nets import inception_resnet_v2\n",
    "from nets import alexnet\n",
    "from nets import nets_factory\n",
    "from preprocessing import inception_preprocessing\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIGURE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"inception_resnet_v2\"\n",
    "model2 = \"alexnet_v2\"\n",
    "\n",
    "dataset_name = \"cve_diseases\"\n",
    "dataset_split_name = \"train\"\n",
    "dataset_dir = \"tmp/\"\n",
    "batch_size = 1\n",
    "max_number_of_steps = 20\n",
    "train_dir = \"./tmp/cve_diseases-models/test-model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size=8, height=299, width=299, is_training=False):\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)\n",
    "\n",
    "    image, label = data_provider.get(['image', 'label'])\n",
    "\n",
    "    image = inception_preprocessing.preprocess_image(\n",
    "        image,\n",
    "        height,\n",
    "        width,\n",
    "        is_training)\n",
    "\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        allow_smaller_final_batch=True)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cve_diseases.get_split('train', dataset_dir)\n",
    "\n",
    "# load batch of dataset\n",
    "images, labels = load_batch(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    is_training=True)\n",
    "\n",
    "# run the image through the model\n",
    "cnn1 = nets_factory.get_network_fn(\n",
    "    model1,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=True)\n",
    "cnn2 = nets_factory.get_network_fn(\n",
    "    model2,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=True)\n",
    "net1, end_points1 = cnn1(images)\n",
    "net2, end_points2 = cnn2(images)\n",
    "reshaped = tf.reshape(end_points2['alexnet_v2/pool5'], [1, 1536])\n",
    "tf.shape(net1)\n",
    "tf.shape(net2)\n",
    "net = tf.concat([net1, net2], 1)\n",
    "net = slim.flatten(net)\n",
    "net = slim.dropout(net, 0.8, is_training=True, scope='Dropout')\n",
    "logits = slim.fully_connected(net, 11, activation_fn=None, scope='Logits')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the cross-entropy loss\n",
    "one_hot_labels = slim.one_hot_encoding(\n",
    "    labels,\n",
    "    dataset.num_classes)\n",
    "slim.losses.softmax_cross_entropy(\n",
    "    logits,\n",
    "    one_hot_labels)\n",
    "total_loss = tf.losses.get_total_loss()\n",
    "tf.summary.scalar('loss', total_loss)\n",
    "\n",
    "# use RMSProp to optimize\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9)\n",
    "\n",
    "# create train op\n",
    "train_op = slim.learning.create_train_op(\n",
    "    total_loss,\n",
    "    optimizer,\n",
    "    summarize_gradients=True)\n",
    "\n",
    "# run training\n",
    "slim.learning.train(\n",
    "    train_op,\n",
    "    logdir=train_dir,\n",
    "    number_of_steps=max_number_of_steps,\n",
    "    log_every_n_steps=10,\n",
    "    save_summaries_secs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
