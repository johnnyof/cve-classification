from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from textwrap import wrap
import re
import itertools
import tfplot
import matplotlib
import numpy as np
from sklearn.metrics import confusion_matrix
import os


import math
import tensorflow as tf

from datasets import dataset_factory
from nets import nets_factory
from preprocessing import inception_preprocessing
from datasets import cve_diseases
from nets import inception_resnet_v2
from nets import inception_v3


slim = tf.contrib.slim
#Vars

model1 = "inception_resnet_v2"
model2 = "inception_v3"
cnn1 = nets_factory.get_network_fn(
    model1,
    num_classes=None,
    weight_decay=0.00004,
    is_training=False)
cnn2 = nets_factory.get_network_fn(
    model2,
    num_classes=None,
    weight_decay=0.00004,
    is_training=False)


#Functions

def load_batch(dataset, batch_size=8, height=299, width=299, is_training=False):
  data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)

  image, label = data_provider.get(['image', 'label'])

  image = inception_preprocessing.preprocess_image(
    image,
    height,
    width,
    is_training)

  images, labels = tf.train.batch(
    [image, label],
    batch_size=batch_size,
    allow_smaller_final_batch=True)

  return images, labels

def jonet(images):


  net1, end_points1 = cnn1(images)
  net1 = end_points1['Mixed_7a']

  net2, end_points2 = cnn2(images)
  net2 = end_points2['Mixed_7c']
  net = tf.concat((net1, net2), 3)
  net = slim.flatten(net)
  net = slim.dropout(net, 0.8, is_training=True)
  net = slim.fully_connected(net, 11, activation_fn=None)
  return net

def eval_confusion_matrix(labels, predictions, num_classes=11):
    with tf.variable_scope("eval_confusion_matrix"):
        con_matrix = tf.confusion_matrix(labels=labels, predictions=predictions, num_classes=num_classes)

        con_matrix_sum = tf.Variable(tf.zeros(shape=(11,11), dtype=tf.int32),
                                            trainable=False,
                                            name="confusion_matrix_result",
                                            collections=[tf.GraphKeys.LOCAL_VARIABLES])


        update_op = tf.assign_add(con_matrix_sum, con_matrix)

        return tf.convert_to_tensor(con_matrix_sum), update_op


def main(_):
#*********************
# Evaluating Metrics *
#*********************
  with tf.Graph().as_default():
      tf_global_step = tf.train.get_or_create_global_step()
      # Create model and obtain the predictions:
      dataset = cve_diseases.get_split('validation', './tmp')
      images, labels = load_batch(dataset, 100, is_training=False)
      predictions = jonet(images)
      predictions = tf.to_int64(tf.argmax(predictions, 1))


      # Choose the metrics to compute:
      names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
        'mse': tf.metrics.mean_squared_error(labels, predictions),
        'accuracy': tf.contrib.metrics.streaming_accuracy(predictions, labels),
        'conv_matrix': eval_confusion_matrix(predictions, labels, 11)
      })

      for name, value in names_to_values.items():
          summary_name = 'eval/%s' % name
          op = tf.summary.scalar(summary_name, tf.squeeze(value), collections=[])
          op = tf.Print(op, [value], summary_name)
          tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)



      checkpoint_dir = tf.train.latest_checkpoint('./tmp/cve_diseases-models/test-model11')
      log_dir = './tmp/cve_diseases-models/test-model11/eval'
      variables_to_restore = slim.get_variables_to_restore()
      # We'll evaluate 1000 batches:
      num_evals = 100
      # Evaluate every 10 minutes:

      slim.evaluation.evaluate_once(
          '',
          checkpoint_path=checkpoint_dir,
          logdir=log_dir,
          num_evals=num_evals,
          eval_op=list(names_to_updates.values()),
          variables_to_restore=variables_to_restore)


if __name__ == '__main__':
  tf.app.run()
