import os
import tensorflow as tf


from datasets import cve_diseases
from nets import inception_resnet_v2
from nets import alexnet_v2
from preprocessing import inception_preprocessing


slim = tf.contrib.slim

################################################################################
tf.app.flags.DEFINE_integer(
    'task', 0, 'Task id of the replica running the training.')



################################################################################
#Helper vars
dataset_dir = "./tmp"
dataset_name = "cve_diseases"
dataset_split_name = "train"


################################################################################
with tf.Graph().as_default():
    deploy_config = model_deploy.DeploymentConfig(
        num_clones=1,
        clone_on_cpu=False,
        replica_id=FLAGS.task,
        num_replicas=1,
        num_ps_tasks=0)

    with tf.device(deploy_config.variables_device()):
        global_step = slim.create_global_step()

    dataset = dataset_factory.get_dataset(dataset_name, dataset_split_name, dataset_dir)

    cnn1 = nets_factory.get_network_fn(
        model1,
        num_classes=11,
        weight_decay=0.00004,
        is_training=True)

    cnn2 = nets_factory.get_network_fn(
        model2,
        num_classes=11,
        weight_decay=0.00004,
        is_training=True)

    preprocessing = inception
    image_preprocessing_fn = preprocessing_factory.get_preprocessing(
        preprocessing,
        is_training=True)

    with tf.device(deploy_config.inputs_device()):
        provider = slim.dataset_data_provider.DatasetDataProvider(
            dataset,
            num_readers=1,
            common_queue_capacity=20 * batch_size,
            common_queue_min=10 * batch_size)
        [image, label] = provider.get(['image', 'label'])

        cnn1_train_size = cnn1.default_image_size
        cnn2_train_size = cnn2.default_image_size

        image = image_preprocessing_fn(image, cnn1_train_size, cnn1_train_size)
        image2 = image_preprocessing_fn(image, cnn2_train_size, cnn2_train_size)

        images, labels = tf.train.batch(
            [image, label],
            batch_size=batch_size,
            num_threads=4,
            capacity=5 * batch_size)

        batch_queue = slim.prefetch_queue.prefetch_queue(
            [images, labels], capacity=2 * deploy_config.num_clones)

    def clone_fn(batch_queue):
      """Allows data parallelism by creating multiple clones of network_fn."""
      images, labels = batch_queue.dequeue()
      logits, end_points = network_fn(images)

      #############################
      # Specify the loss function #
      #############################
      if 'AuxLogits' in end_points:
        slim.losses.softmax_cross_entropy(
            end_points['AuxLogits'], labels,
            label_smoothing=FLAGS.label_smoothing, weights=0.4,
            scope='aux_loss')
      slim.losses.softmax_cross_entropy(
          logits, labels, label_smoothing=FLAGS.label_smoothing, weights=1.0)
      return end_points
