import tensorflow as tf
from datasets import cve_diseases
from nets import inception_resnet_v2
from nets import alexnet
from nets import nets_factory
from preprocessing import inception_preprocessing


slim = tf.contrib.slim
metrics = tf.contrib.metrics

flags = tf.app.flags
flags.DEFINE_string('data_dir', '/tmp/mnist',
                    'Directory with the MNIST data.')
flags.DEFINE_integer('batch_size', 1, 'Batch size.')
flags.DEFINE_integer('eval_interval_secs', 60,
                    'Number of seconds between evaluations.')
flags.DEFINE_integer('num_evals', 1000, 'Number of batches to evaluate.')
flags.DEFINE_string('log_dir', './log/eval',
                    'Directory where to log evaluation data.')
flags.DEFINE_string('checkpoint_dir', './log/train',
                    'Directory with the model checkpoint data.')
FLAGS = flags.FLAGS
model1 = "inception_resnet_v2"
model2 = "alexnet_v2"
cnn1 = nets_factory.get_network_fn(
    model1,
    num_classes=None,
    weight_decay=0.00004,
    is_training=False)
cnn2 = nets_factory.get_network_fn(
    model2,
    num_classes=None,
    weight_decay=0.00004,
    is_training=False)

def jonet(images):

    net1, end_points1 = cnn1(images)
    net2, end_points2 = cnn2(images)
    if 'PreAuxLogits' in end_points1:
        if 'alexnet_v2/conv4' in end_points2:

            net1 = end_points1['PreAuxLogits']
            net1 = slim.conv2d(net1, 256, 1)
            net2 = end_points2['alexnet_v2/conv5']
            net = tf.concat((net1, net2), 1)
            net = slim.flatten(net)
            net = slim.dropout(net, 0.8, is_training=True)
            net = slim.fully_connected(net, 11, activation_fn=None)
            return net

def load_batch(dataset, batch_size=8, height=299, width=299, is_training=False):
    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)

    image, label = data_provider.get(['image', 'label'])

    image = inception_preprocessing.preprocess_image(
        image,
        height,
        width,
        is_training)

    images, labels = tf.train.batch(
        [image, label],
        batch_size=batch_size,
        allow_smaller_final_batch=True)

    return images, labels


def main(args):
    # load the dataset
    dataset = cve_diseases.get_split('validation', FLAGS.data_dir)

    # load batch
    images, labels = load_batch(
        dataset,
        FLAGS.batch_size,
        is_training=False)

    # get the model prediction
    predictions = jonet(images)

    # convert prediction values for each class into single class prediction
    predictions = tf.to_int64(tf.argmax(predictions, 1))

    # streaming metrics to evaluate
    metrics_to_values, metrics_to_updates = metrics.aggregate_metric_map({
        'mse': metrics.streaming_mean_squared_error(predictions, labels),
        'accuracy': metrics.streaming_accuracy(predictions, labels),
    })

    # write the metrics as summaries
    for metric_name, metric_value in metrics_to_values.iteritems():
        tf.summary.scalar(metric_name, metric_value)

    # evaluate on the model saved at the checkpoint directory
    # evaluate every eval_interval_secs
    slim.evaluation.evaluation_loop(
        '',
        FLAGS.checkpoint_dir,
        FLAGS.log_dir,
        num_evals=FLAGS.num_evals,
        eval_op=metrics_to_updates.values(),
        eval_interval_secs=FLAGS.eval_interval_secs)


if __name__=='__main__':
    tf.app.run()
