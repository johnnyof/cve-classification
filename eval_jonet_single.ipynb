{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from datasets import dataset_utils\n",
    "from datasets import cve_diseases\n",
    "from nets import inception_resnet_v2\n",
    "from nets import alexnet\n",
    "from nets import nets_factory\n",
    "from preprocessing import inception_preprocessing\n",
    "# Main slim library\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"inception_resnet_v2\"\n",
    "model2 = \"inception_v3\"\n",
    "\n",
    "dataset_name = \"cve_diseases\"\n",
    "dataset_split_name = \"validation\"\n",
    "dataset_dir = \"tmp/\"\n",
    "batch_size = 100\n",
    "max_number_of_steps = 100000\n",
    "train_dir = \"./tmp/cve_diseases-models/model2-ds2\"\n",
    "\n",
    "cnn1 = nets_factory.get_network_fn(\n",
    "    model1,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=False)\n",
    "cnn2 = nets_factory.get_network_fn(\n",
    "    model2,\n",
    "    num_classes=None,\n",
    "    weight_decay=0.00004,\n",
    "    is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jonet(images):\n",
    "\n",
    "    net, end_points1 = cnn1(images)\n",
    "    #net1 = end_points1['Mixed_7a']\n",
    "    \n",
    "    #net2, end_points2 = cnn2(images)\n",
    "    #net2 = end_points2['Mixed_7c']\n",
    "    #net = tf.concat((net1, net2), 3)\n",
    "    net = slim.flatten(net)\n",
    "    net = slim.dropout(net, 0.8, is_training=False)\n",
    "    net = slim.fully_connected(net, 11, activation_fn=None)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size=8, height=299, width=299, is_training=False):\n",
    "    \n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)\n",
    "\n",
    "    image_raw, label = data_provider.get(['image', 'label'])\n",
    "    \n",
    "    # Preprocess image for usage by Inception.\n",
    "    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n",
    "    \n",
    "    # Preprocess the image for display purposes.\n",
    "    image_raw = tf.expand_dims(image_raw, 0)\n",
    "    image_raw = tf.image.resize_images(image_raw, [height, width])\n",
    "    image_raw = tf.squeeze(image_raw)\n",
    "\n",
    "    # Batch it up.\n",
    "    images, images_raw, labels = tf.train.batch(\n",
    "          [image, image_raw, label],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=1,\n",
    "          capacity=2 * batch_size)\n",
    "    \n",
    "    return images, images_raw, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "image_size = 299\n",
    "batch_size = 400\n",
    "imgs = 10\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    dataset = cve_diseases.get_split('validation', dataset_dir)\n",
    "    images, images_raw, labels = load_batch(dataset, batch_size)\n",
    "    \n",
    "    # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "\n",
    "    logits = jonet(images)\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    con_mat = tf.confusion_matrix(\n",
    "        labels=labels,\n",
    "        predictions=tf.argmax(probabilities, 1))\n",
    "    \n",
    "    \n",
    "    predictions = tf.argmax(probabilities, 1)\n",
    "    accuracy = tf.metrics.accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "    checkpoint_path = tf.train.latest_checkpoint(train_dir)\n",
    "    \n",
    "    \n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "      checkpoint_path,\n",
    "      slim.get_variables_to_restore())\n",
    "    print(tf.argmax(labels))\n",
    "    with tf.Session() as sess:\n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            sess.run(tf.initialize_local_variables())\n",
    "            init_fn(sess)\n",
    "            accuracy, np_predictions, np_probabilities, np_images_raw, np_labels, con_mat = sess.run([accuracy, predictions, probabilities, images_raw, labels, con_mat])\n",
    "            \n",
    "            \n",
    "            plt.imshow(con_mat, interpolation='nearest', cmap=plt.cm.viridis);\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.colorbar()\n",
    "            plt.clim(0,30)\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel(\"True label\")\n",
    "            plt.xlabel(\"Predicted label\")\n",
    "            plt.show()\n",
    "            print(con_mat)\n",
    "\n",
    "            precision, recall, f1, _ = score(np_labels, np_predictions, average='macro')\n",
    "\n",
    "            print('precision: {}'.format(precision))\n",
    "            print('recall: {}'.format(recall))\n",
    "            print('fscore: {}'.format(f1))\n",
    "            print('accuracy: {}'.format(accuracy))\n",
    "\n",
    "            for i in range(imgs): \n",
    "                image = np_images_raw[i, :, :, :]\n",
    "                true_label = np_labels[i]\n",
    "                predicted_label = np.argmax(np_probabilities[i, :])\n",
    "                predicted_name = dataset.labels_to_names[predicted_label]\n",
    "                true_name = dataset.labels_to_names[true_label]\n",
    "                \n",
    "                \n",
    "                plt.figure()\n",
    "                plt.imshow(image.astype(np.uint8))\n",
    "                plt.title('Ground Truth: [%s], Prediction [%s]' % (true_name, predicted_name))\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
